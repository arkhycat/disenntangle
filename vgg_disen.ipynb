{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b64b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import argparse\n",
    "import enum\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import json\n",
    "from models import block_regularizer, compute_layer_blocks_in, compute_layer_blocks_out\n",
    "from spectral_utils import normalize_w\n",
    "\n",
    "from three_d_shapes_ds import ThreeDShapes\n",
    "from col_mnist import ColMNIST\n",
    "from models import DisentangledLinear, BlockDropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c14bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%d.%m.%Y(%H:%M:%S)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3f68782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupportedDatasets(enum.Enum):\n",
    "    THREEDSHAPES = 0,\n",
    "    COL_MNIST = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13e6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!export CUDA_VISIBLE_DEVICES=2,5\n",
    "#!echo $CUDA_VISIBLE_DEVICES\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f20828b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Config {\n",
      "    \"dataset\": \"COL_MNIST\",\n",
      "    \"input_layer\": \"cl0\",\n",
      "    \"output_layer\": \"cl3\",\n",
      "    \"blocks\": 2,\n",
      "    \"layer_size\": 4096,\n",
      "    \"prune_by\": 2048,\n",
      "    \"data_dir\": \"data\",\n",
      "    \"load_model\": null,\n",
      "    \"save_dir\": \"28.09.2021(10:04:20)\",\n",
      "    \"deterministic\": false,\n",
      "    \"gpus\": \"2\",\n",
      "    \"batch_size\": 8,\n",
      "    \"n_epochs\": 30,\n",
      "    \"dropout_p\": 0.8,\n",
      "    \"optimizer\": \"SGD\"\n",
      "}\n",
      "INFO:root:Using cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving and logging to 28.09.2021(10:04:20)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Common params\n",
    "parser.add_argument(\"--dataset\", type=str, choices=[ds.name for ds in SupportedDatasets], help=\"\", \n",
    "                    default=SupportedDatasets.COL_MNIST.name)\n",
    "parser.add_argument(\"--input_layer\", type=str, help=\"Layer to disentangle\", default='cl0')\n",
    "parser.add_argument(\"--output_layer\", type=str, help=\"Layer to disentangle\", default='cl3')\n",
    "parser.add_argument(\"--blocks\", type=int, help=\"Number of blocks\", default=2)\n",
    "parser.add_argument(\"--layer_size\", type=int, help=\"Size of the disentangled layer\", default=4096)\n",
    "parser.add_argument(\"--prune_by\", type=int, help=\"How many neurons we want to remove\", default=2048)\n",
    "parser.add_argument(\"--data_dir\", type=str, help=\"Directory to load data from\", default='data')\n",
    "parser.add_argument(\"--load_model\", type=str, help=\"\")\n",
    "parser.add_argument(\"--save_dir\", type=str, help=\"Directory to save models, logs and plots to\", \n",
    "                    default=os.path.join(\"outputs\", timestampStr))\n",
    "parser.add_argument(\"--deterministic\", type=bool, help=\"\", default=False)\n",
    "parser.add_argument(\"--gpus\", type=str, help=\"\", default=None)\n",
    "parser.add_argument(\"--batch_size\", type=int, help=\"\", default=8)\n",
    "parser.add_argument(\"--n_epochs\", type=int, help=\"\", default=30)\n",
    "parser.add_argument(\"--dropout_p\", type=float, help=\"Probability of block dropout\", default=0.8)\n",
    "parser.add_argument(\"--optimizer\", type=str, help=\"Optimizer\", choices=[\"SGD\", \"Adam\"], default=\"SGD\")\n",
    "\n",
    "args = parser.parse_args(['--gpus', '2'])  # important to put '' in Jupyter otherwise it will complain\n",
    "\n",
    "config = dict()\n",
    "# Wrapping configuration into a dictionary\n",
    "for arg in vars(args):\n",
    "    config[arg] = getattr(args, arg)\n",
    "    \n",
    "if not os.path.exists(config[\"save_dir\"]):\n",
    "    os.makedirs(config[\"save_dir\"])\n",
    "    \n",
    "#logging.basicConfig(filename=os.path.join(config[\"save_dir\"], \"run.log\"), level=logging.DEBUG)\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "config['data_dir'] = os.path.basename(config['data_dir'])  # handle absolute and relative paths\n",
    "config['save_dir'] = os.path.basename(config['save_dir'])\n",
    "print(\"Saving and logging to {}\".format(config['save_dir']))\n",
    "\n",
    "if config['deterministic']:\n",
    "    torch.manual_seed(123)\n",
    "    torch.cuda.manual_seed(123)\n",
    "    np.random.seed(123)\n",
    "    random.seed(123)\n",
    "    torch.backends.cudnn.enabled=False\n",
    "    torch.backends.cudnn.deterministic=True\n",
    "\n",
    "device = \"cpu\"\n",
    "if len(config[\"gpus\"]) > 0:\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\",\".join(config[\"gpus\"])\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #change to actual args\n",
    "    \n",
    "logging.info(\"Config {}\".format(json.dumps(config, indent=4)))\n",
    "logging.info(\"Using {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cfef5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"dataset\"] == SupportedDatasets.THREEDSHAPES.name:\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "                                          ThreeDShapes(filename=os.path.join(config[\"data_dir\"], \"3dshapes.h5\"),\n",
    "                                                       transform=torchvision.transforms.Compose([\n",
    "                                                           torchvision.transforms.ToPILImage(), \n",
    "                                                           torchvision.transforms.Resize((32, 32)),\n",
    "                                                           torchvision.transforms.ToTensor()]), filtered = True),\n",
    "                                          batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "                                          ThreeDShapes(filename=os.path.join(config[\"data_dir\"], \"3dshapes.h5\"),\n",
    "                                                       transform=torchvision.transforms.Compose([\n",
    "                                                           torchvision.transforms.ToPILImage(), \n",
    "                                                           torchvision.transforms.Resize((32, 32)),\n",
    "                                                           torchvision.transforms.ToTensor()]), filtered = True),\n",
    "                                          batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    n_classes = 16\n",
    "    def target_vec_to_class(vec):\n",
    "        labels = (vec[:, 0] == 0).int()*(2**3) + (vec[:, 1] == 0).int()*(2**2) + (vec[:, 2] == 0)*2 + (vec[:, 4] == 0)\n",
    "        return labels.long()\n",
    "    \n",
    "elif config[\"dataset\"] == SupportedDatasets.COL_MNIST.name:\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "      ColMNIST(os.path.join(config[\"data_dir\"], \"mnist\"), train=True, download=True,\n",
    "                                 transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor(),\n",
    "                                 ])),\n",
    "      batch_size=config[\"batch_size\"], shuffle=True)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "      ColMNIST(os.path.join(config[\"data_dir\"], \"mnist\"), train=False, download=True,\n",
    "                                 transform=torchvision.transforms.Compose([\n",
    "                                   torchvision.transforms.ToTensor()\n",
    "                                 ])),\n",
    "      batch_size=config[\"batch_size\"], shuffle=True)\n",
    "    \n",
    "    n_classes = 30\n",
    "    def target_vec_to_class(tpl):\n",
    "        (target, dclr_idx, bclr_idx) = tpl\n",
    "        target += bclr_idx*10\n",
    "        return target.long()\n",
    "\n",
    "else:\n",
    "    logging.error(\"Dataset not supported\")\n",
    "    \n",
    "for data, target in testloader:\n",
    "    break\n",
    "img_shape = data.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcb49e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#config[\"load_model\"] = \"models/vgg16disen_colmnist_e29.pt\"\n",
    "if config[\"load_model\"] is not None:\n",
    "    vgg16 = torch.load(config[\"load_model\"])\n",
    "else:\n",
    "    vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "344eba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): DisentangledLinear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BlockDropout(\n",
      "      p=0.8, inplace=False\n",
      "      (layer): DisentangledLinear(in_features=4096, out_features=4096, bias=True)\n",
      "    )\n",
      "    (3): DisentangledLinear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "ncc = config[\"blocks\"] #number of connected components\n",
    "#TODO: add option of not specifying layer size in case we're loading\n",
    "\n",
    "if config[\"input_layer\"]==\"cl3\" and config[\"output_layer\"]==\"cl6\":\n",
    "    vgg16.classifier[3] = DisentangledLinear(vgg16.classifier[3].in_features, config[\"layer_size\"]).to(device)\n",
    "    vgg16.classifier[6] = DisentangledLinear(config[\"layer_size\"], n_classes).to(device)\n",
    "    vgg16.classifier[5] = BlockDropout(vgg16.classifier[6], ncc=ncc, p=config[\"dropout_p\"], apply_to=\"in\")\n",
    "elif config[\"input_layer\"]==\"cl0\" and config[\"output_layer\"]==\"cl3\":\n",
    "    # disentangle layers right after convolutions\n",
    "    vgg16.classifier[0] = DisentangledLinear(vgg16.classifier[0].in_features, config[\"layer_size\"]).to(device)\n",
    "    vgg16.classifier[3] = DisentangledLinear(config[\"layer_size\"], vgg16.classifier[3].out_features).to(device)\n",
    "    vgg16.classifier[2] = BlockDropout(vgg16.classifier[3], ncc=ncc, p=config[\"dropout_p\"], apply_to=\"in\")\n",
    "else:\n",
    "    logging.error(\"Layer combination not supported\")\n",
    "\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "logging.info(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48f15860",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config[\"optimizer\"] == \"Adam\":\n",
    "    optimizer = optim.Adam(vgg16.classifier.parameters(), lr=0.001)\n",
    "else:\n",
    "    optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001, momentum=0.9)\n",
    "# loss function\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12b6b3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation function\n",
    "def validate(model, test_dataloader):\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    for int, data in enumerate(test_dataloader):\n",
    "        data, target = data[0], data[1]\n",
    "        target = target_vec_to_class(target)\n",
    "        \n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        \n",
    "        val_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        val_running_correct += (preds == target).sum().item()\n",
    "    \n",
    "    val_loss = val_running_loss/len(test_dataloader.dataset)\n",
    "    val_accuracy = 100. * val_running_correct/len(test_dataloader.dataset)\n",
    "    logging.info(f'Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}')\n",
    "    \n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def neuron_wise_br(model, layer, blocks, examples, ncc):\n",
    "    model.eval()\n",
    "    br_wo_neuron = [np.inf]*layer.out_features\n",
    "    for n in range(layer.out_features):\n",
    "        if layer.out_mask is not None:\n",
    "            mask = torch.clone(layer.out_mask)\n",
    "        else:\n",
    "            mask = torch.ones(layer.out_features, dtype=torch.bool)\n",
    "        if mask[n] > 0:\n",
    "            mask[n] = 0\n",
    "            a_n = normalize_w(layer.weight[mask])\n",
    "            _, s, _ = torch.svd(a_n)\n",
    "            br_wo_neuron[n] = ncc - torch.sum(s[:ncc]).detach().cpu()\n",
    "    return br_wo_neuron\n",
    "\n",
    "def plot_blocked_weights(layer):\n",
    "    plt.figure(figsize=(20, 7))\n",
    "    blocks_in = compute_layer_blocks_in(layer, ncc)\n",
    "    blocks_out = compute_layer_blocks_out(layer, ncc)\n",
    "    plt.imshow(layer.weight[np.argsort(blocks_out)][:, np.argsort(blocks_in)].cpu().detach().numpy())\n",
    "    plt.show()\n",
    "    \n",
    "def prune(model, layer_out, layer_in, ncc):\n",
    "    blocks = compute_layer_blocks_in(layer_out, ncc)\n",
    "    for batch_features in testloader:\n",
    "        batch_features = batch_features[0]\n",
    "        test_examples = batch_features.to(device)\n",
    "        break\n",
    "    re = neuron_wise_br(model, layer_in, blocks, test_examples, ncc)\n",
    "    removal_mask = layer_in.out_mask\n",
    "    if removal_mask is None:\n",
    "        removal_mask = torch.ones(layer_in.out_features, dtype=torch.bool)\n",
    "    removal_mask[np.argmin(re)] = 0\n",
    "    layer_out.turn_input_neurons_off(removal_mask)\n",
    "    layer_in.turn_output_neurons_off(removal_mask)\n",
    "    logging.info(\"Pruned to {} neurons\".format(layer_out.in_mask.sum().item()))\n",
    "    \n",
    "def fit(model, train_dataloader, prune_every_n_steps):\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        data, target = data[0], data[1]\n",
    "        target = target_vec_to_class(target)\n",
    "        \n",
    "        #data = data.to(device)\n",
    "        #target = target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        block_reg = block_regularizer(model.module.classifier[3], ncc)\n",
    "        loss = criterion(output.cpu(), target)# + block_reg\n",
    "        #loss = block_reg\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        train_running_correct += (preds.cpu() == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i)%prune_every_n_steps == 0:\n",
    "            logging.info(\"Block regularizer \"+str(block_reg.item()))\n",
    "            #plot_blocked_weights(vgg16.classifier[6])\n",
    "            #plot_blocked_weights(vgg16.classifier[3])\n",
    "            if config[\"input_layer\"]==\"cl3\" and config[\"output_layer\"]==\"cl6\":\n",
    "                prune(model.module, model.module.classifier[6], model.module.classifier[3], ncc)\n",
    "            if config[\"input_layer\"]==\"cl0\" and config[\"output_layer\"]==\"cl3\":\n",
    "                prune(model.module, model.module.classifier[3], model.module.classifier[0], ncc)\n",
    "            \n",
    "    train_loss = train_running_loss/len(train_dataloader.dataset)\n",
    "    train_accuracy = 100. * train_running_correct/len(train_dataloader.dataset)\n",
    "    logging.info(f'Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}')\n",
    "    \n",
    "    return train_loss, train_accuracy, block_reg.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a3952c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = config[\"n_epochs\"]\n",
    "total_batches = len(trainloader)*n_epochs\n",
    "layer_size_reduction = config[\"prune_by\"]\n",
    "prune_every_n_steps = int(round(total_batches/(layer_size_reduction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988ab058",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_parallel = nn.DataParallel(vgg16, device_ids = [0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834edd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch 0\n",
      "INFO:root:Block regularizer 0.9821493625640869\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5089/99043577.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_every_n_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mval_epoch_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_epoch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvgg16_parallel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_epoch_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5089/1529674655.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, train_dataloader, prune_every_n_steps)\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"cl0\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"output_layer\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"cl3\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mprune\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_running_loss\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5089/1529674655.py\u001b[0m in \u001b[0;36mprune\u001b[0;34m(model, layer_out, layer_in, ncc)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mtest_examples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_wise_br\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0mremoval_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_in\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mremoval_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_5089/1529674655.py\u001b[0m in \u001b[0;36mneuron_wise_br\u001b[0;34m(model, layer, blocks, examples, ncc)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0ma_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mbr_wo_neuron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mncc\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mncc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbr_wo_neuron\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss , train_accuracy = [], []\n",
    "val_loss , val_accuracy, br = [], [], []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(n_epochs):\n",
    "    start_e = time.time()\n",
    "    logging.info(\"Epoch {}\".format(epoch))\n",
    "    train_epoch_loss, train_epoch_accuracy, block_reg = fit(vgg16_parallel, trainloader, prune_every_n_steps)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(vgg16_parallel, testloader)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    br.append(block_reg)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "    torch.save(vgg16_parallel.module, os.path.join(config[\"save_dir\"], \"model.pt\"))\n",
    "    end_e = time.time()\n",
    "    logging.info('Epoch {} took {} minutes '.format(epoch+1, (end-start)/60))\n",
    "    \n",
    "end = time.time()\n",
    "logging.info('{} minutes in total'.format((end-start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b170f05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d11d5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
