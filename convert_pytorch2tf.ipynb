{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "MODEL_DIR = \"outputs/onnx_test\"\n",
    "#vgg16 = torch.load(os.path.join(MODEL_DIR, \"model.pt\"))\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "vgg16 = vgg16.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73fee104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DisentangledLinear\n",
    "import torch.nn as nn\n",
    "from collections import namedtuple\n",
    "\n",
    "class Vgg16Experimental(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, vgg16, requires_grad=False, show_progress=False):\n",
    "        super().__init__()\n",
    "        vgg_pretrained_features = vgg16.features\n",
    "\n",
    "        # I've exposed the best/most interesting layers in my subjective opinion (mp5 is not that good though)\n",
    "        self.layer_names = ['relu3_3', 'relu4_1', 'relu4_2', 'relu4_3', 'relu5_1', 'relu5_2', 'relu5_3', 'mp5', 'ap', \"relu_cl1\", \"relu_cl2\"]\n",
    "\n",
    "        # 31 layers in total for the VGG16\n",
    "        self.conv1_1 = vgg_pretrained_features[0]\n",
    "        self.relu1_1 = vgg_pretrained_features[1]\n",
    "        self.conv1_2 = vgg_pretrained_features[2]\n",
    "        self.relu1_2 = vgg_pretrained_features[3]\n",
    "        self.max_pooling1 = vgg_pretrained_features[4]\n",
    "        self.conv2_1 = vgg_pretrained_features[5]\n",
    "        self.relu2_1 = vgg_pretrained_features[6]\n",
    "        self.conv2_2 = vgg_pretrained_features[7]\n",
    "        self.relu2_2 = vgg_pretrained_features[8]\n",
    "        self.max_pooling2 = vgg_pretrained_features[9]\n",
    "        self.conv3_1 = vgg_pretrained_features[10]\n",
    "        self.relu3_1 = vgg_pretrained_features[11]\n",
    "        self.conv3_2 = vgg_pretrained_features[12]\n",
    "        self.relu3_2 = vgg_pretrained_features[13]\n",
    "        self.conv3_3 = vgg_pretrained_features[14]\n",
    "        self.relu3_3 = vgg_pretrained_features[15]\n",
    "        self.max_pooling3 = vgg_pretrained_features[16]\n",
    "        self.conv4_1 = vgg_pretrained_features[17]\n",
    "        self.relu4_1 = vgg_pretrained_features[18]\n",
    "        self.conv4_2 = vgg_pretrained_features[19]\n",
    "        self.relu4_2 = vgg_pretrained_features[20]\n",
    "        self.conv4_3 = vgg_pretrained_features[21]\n",
    "        self.relu4_3 = vgg_pretrained_features[22]\n",
    "        self.max_pooling4 = vgg_pretrained_features[23]\n",
    "        self.conv5_1 = vgg_pretrained_features[24]\n",
    "        self.relu5_1 = vgg_pretrained_features[25]\n",
    "        self.conv5_2 = vgg_pretrained_features[26]\n",
    "        self.relu5_2 = vgg_pretrained_features[27]\n",
    "        self.conv5_3 = vgg_pretrained_features[28]\n",
    "        self.relu5_3 = vgg_pretrained_features[29]\n",
    "        self.max_pooling5 = vgg_pretrained_features[30]\n",
    "        \n",
    "        #self.adaptive_pool = vgg16.avgpool\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d(output_size=(7, 7))\n",
    "        #self.adaptive_pool = nn.AvgPool2d(kernel_size=1,\n",
    "        \n",
    "        self.linear_cl1 = vgg16.classifier[0]\n",
    "        self.relu_cl1 = vgg16.classifier[1]\n",
    "        self.linear_cl2 = vgg16.classifier[3]\n",
    "        self.relu_cl2 = vgg16.classifier[1]\n",
    "        self.linear_cl3 = vgg16.classifier[6]\n",
    "\n",
    "        # Turn off these because we'll be using a pretrained network\n",
    "        # if we didn't do this PyTorch would be saving gradients and eating up precious memory!\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    # Just expose every single layer during the forward pass\n",
    "    def forward(self, x):\n",
    "        x = self.conv1_1(x)\n",
    "        conv1_1 = x\n",
    "        x = self.relu1_1(x)\n",
    "        relu1_1 = x\n",
    "        x = self.conv1_2(x)\n",
    "        conv1_2 = x\n",
    "        x = self.relu1_2(x)\n",
    "        relu1_2 = x\n",
    "        x = self.max_pooling1(x)\n",
    "        x = self.conv2_1(x)\n",
    "        conv2_1 = x\n",
    "        x = self.relu2_1(x)\n",
    "        relu2_1 = x\n",
    "        x = self.conv2_2(x)\n",
    "        conv2_2 = x\n",
    "        x = self.relu2_2(x)\n",
    "        relu2_2 = x\n",
    "        x = self.max_pooling2(x)\n",
    "        x = self.conv3_1(x)\n",
    "        conv3_1 = x\n",
    "        x = self.relu3_1(x)\n",
    "        relu3_1 = x\n",
    "        x = self.conv3_2(x)\n",
    "        conv3_2 = x\n",
    "        x = self.relu3_2(x)\n",
    "        relu3_2 = x\n",
    "        x = self.conv3_3(x)\n",
    "        conv3_3 = x\n",
    "        x = self.relu3_3(x)\n",
    "        relu3_3 = x\n",
    "        x = self.max_pooling3(x)\n",
    "        x = self.conv4_1(x)\n",
    "        conv4_1 = x\n",
    "        x = self.relu4_1(x)\n",
    "        relu4_1 = x\n",
    "        x = self.conv4_2(x)\n",
    "        conv4_2 = x\n",
    "        x = self.relu4_2(x)\n",
    "        relu4_2 = x\n",
    "        x = self.conv4_3(x)\n",
    "        conv4_3 = x\n",
    "        x = self.relu4_3(x)\n",
    "        relu4_3 = x\n",
    "        x = self.max_pooling4(x)\n",
    "        x = self.conv5_1(x)\n",
    "        conv5_1 = x\n",
    "        x = self.relu5_1(x)\n",
    "        relu5_1 = x\n",
    "        x = self.conv5_2(x)\n",
    "        conv5_2 = x\n",
    "        x = self.relu5_2(x)\n",
    "        relu5_2 = x\n",
    "        x = self.conv5_3(x)\n",
    "        conv5_3 = x\n",
    "        x = self.relu5_3(x)\n",
    "        relu5_3 = x\n",
    "        x = self.max_pooling5(x)\n",
    "        mp5 = x\n",
    "        x = self.adaptive_pool(x)\n",
    "        ap = x\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x = self.linear_cl1(x)\n",
    "        lin_cl1 = x\n",
    "        x = self.relu_cl1(x)\n",
    "        relu_cl1 = x\n",
    "        x = self.linear_cl2(x)\n",
    "        lin_cl2 = x\n",
    "        x = self.relu_cl2(x)\n",
    "        relu_cl2 = x\n",
    "        x = self.linear_cl3(x)\n",
    "        lin_cl3 = x\n",
    "\n",
    "        # Finally, expose only the layers that you want to experiment with here\n",
    "        vgg_outputs = namedtuple(\"VggOutputs\", self.layer_names)\n",
    "        out = vgg_outputs(relu3_3, relu4_1, relu4_2, relu4_3, relu5_1, relu5_2, relu5_3, mp5, ap, relu_cl1, relu_cl2)\n",
    "\n",
    "        return out\n",
    "    \n",
    "vgg_e = Vgg16Experimental(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b934dc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from three_d_shapes_ds import ThreeDShapes\n",
    "import torchvision\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "                                      ThreeDShapes(filename='data/3dshapes.h5',\n",
    "                                                   transform=torchvision.transforms.Compose([\n",
    "                                                       torchvision.transforms.ToPILImage(), \n",
    "                                                       torchvision.transforms.Resize((512, 512)),\n",
    "                                                       torchvision.transforms.ToTensor(),\n",
    "                                      ]), filtered = False),\n",
    "                                      batch_size=32, shuffle=True)\n",
    "for d in trainloader:\n",
    "    data, target = d[0].cuda(), d[1]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed3ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade numpy==1.19.2\n",
    "#!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6953c90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 512, 16, 16])\n",
      "torch.Size([32, 512, 7, 7])\n",
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.3368],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1086],\n",
      "        [0.0000, 0.0000, 0.4030,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.1746,  ..., 0.0000, 0.0000, 0.2143],\n",
      "        [0.0000, 0.0000, 0.6016,  ..., 0.0000, 0.0000, 0.2056],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.4375]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "dummy_input = Variable(torch.randn(32, 3, 32, 32)).cuda()\n",
    "print(vgg_e(data).mp5.shape)\n",
    "print(vgg_e(data).ap.shape)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(vgg_e(data).relu_cl2)\n",
    "#ap = vgg_e(data).ap.detach().cpu()\n",
    "#for i in range(512):\n",
    "#    plt.imshow(ap.numpy()[0, i])\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6d748c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaptiveAvgPool2d(output_size=(7, 7))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_e.adaptive_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d456cedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "25088/512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50144f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vgg_s import vgg11\n",
    "vgg_s = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
